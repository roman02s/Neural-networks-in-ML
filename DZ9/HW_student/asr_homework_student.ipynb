{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa26bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import torch\n",
    "import pickle\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# будем использовать mpire для ускорения\n",
    "# на некоторых системах есть проблема с кол-вом открываемвых\n",
    "# файловы дескрипторов, поэтому разрешим нашему процессу\n",
    "# создавать их в большЕм количестве\n",
    "from mpire import WorkerPool\n",
    "import resource\n",
    "soft, hard = resource.getrlimit(resource.RLIMIT_NOFILE)\n",
    "resource.setrlimit(resource.RLIMIT_NOFILE, (hard, hard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0310a517",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_CTC_DATASET_PATH = './test_data.pt'\n",
    "VOCAB_PKL_PATH = './vocab.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61ceb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.load(TEST_CTC_DATASET_PATH)\n",
    "with open(VOCAB_PKL_PATH, 'rb') as fin:\n",
    "    vocab_dict = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0451148",
   "metadata": {},
   "source": [
    "# Часть 1. Метрики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8df8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# поможем себе с расстоянием Левенштейна\n",
    "import Levenshtein\n",
    "\n",
    "# Будем использовать эту функцию для нормализации текстов перед замером CER / WER\n",
    "ALLOWED_SYMBOLS = re.compile(r\"(^[a-zа-я\\s]+$)\")\n",
    "def normalize_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    В датасетах, иногда встречается '-', 'ё', апострофы и большие буквы. А мы хотим, чтобы:\n",
    "        WER(\"Ростов-на-дону\", \"ростов на дону\") == 0\n",
    "        WER(\"It's\", \"it s\") == 0\n",
    "        WER(\"ёлки палки\", \"елки палки\") == 0\n",
    "    Поэтому заменяем в target'ах 'ё' на 'е', а '-' на ' ' и т. д.\n",
    "    Кроме того на всякий случай удаляем лишние пробелы.\n",
    "    И проверяем что в получившейся строке только допустимые символы.\n",
    "    \"\"\"\n",
    "    assert isinstance(text, str)\n",
    "    text = text.lower().strip().replace(\"ё\", \"е\")\n",
    "    text = re.sub(r\"\\W+\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    text = text.strip().split(\" \")\n",
    "    text = \" \".join(word for word in text if len(word) > 0)\n",
    "    assert (text == \"\") or ALLOWED_SYMBOLS.match(text)\n",
    "    return text\n",
    "\n",
    "def wer(ground_truth: str, predicted: str) -> float:\n",
    "    # Здесь должен быть ваш код, который будет оцениваться\n",
    "    raise NotImplemented('Please, implement me!')\n",
    "\n",
    "def cer(ground_truth: str, predicted: str) -> float:\n",
    "    # Здесь должен быть ваш код, который будет оцениваться\n",
    "    raise NotImplemented('Please, implement me!')\n",
    "\n",
    "# Функции для расчета relative CER / WER\n",
    "# В функции нужно подавать строки обработанные методом normalize_text\n",
    "def relative_cer(ground_truth: str, predicted: str) -> float:\n",
    "    assert isinstance(ground_truth, str)\n",
    "    assert isinstance(predicted, str)\n",
    "    return min(1, cer(ground_truth, predicted) / (len(ground_truth) + 1e-10))\n",
    "\n",
    "def relative_wer(ground_truth: str, predicted: str) -> float:\n",
    "    assert isinstance(ground_truth, str)\n",
    "    assert isinstance(predicted, str)\n",
    "    gt_len = ground_truth.count(\" \") + 1\n",
    "    return min(1, wer(ground_truth, predicted) / (gt_len + 1e-10))\n",
    "\n",
    "# Функции для расчета ORACLE relative CER / WER - тут мы выбираем лучшую гипотезу из beam'a\n",
    "# В функции нужно подавать строки обработанные методом normalize_text\n",
    "def oracle_relative_cer(ground_truth: str, predicted: List[str]) -> float:\n",
    "    return min(relative_cer(ground_truth, hypo) for hypo in predicted)\n",
    "\n",
    "def oracle_relative_wer(ground_truth: str, predicted: List[str]) -> float:\n",
    "    return min(relative_wer(ground_truth, hypo) for hypo in predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3923611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тесты для проверки правильности реализации cer/wer \n",
    "assert(cer(normalize_text(\"алёнка родила девчёнку\"), normalize_text(\"аленка радила девченку Инну\")) == 6)\n",
    "assert(wer(normalize_text(\"алёнка родила девчёнку\"), normalize_text(\"аленка радила девченку Инну\")) == 2)\n",
    "\n",
    "assert(cer(normalize_text(\"\"), normalize_text(\"\")) == 0)\n",
    "assert(wer(normalize_text(\"\"), normalize_text(\"\")) == 0)\n",
    "\n",
    "assert(cer(normalize_text(\"Ростов-на-дону\"), normalize_text(\"ростов на дону\")) == 0)\n",
    "assert(wer(normalize_text(\"Ростов-на-дону\"), normalize_text(\"ростов на дону\")) == 0)\n",
    "\n",
    "assert(cer(normalize_text(\"It's\"), normalize_text(\"it s\")) == 0)\n",
    "assert(wer(normalize_text(\"It's\"), normalize_text(\"it s\")) == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f68bea6",
   "metadata": {},
   "source": [
    "# Часть 2. CTC декодинг."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8612ca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTCDecoder:\n",
    "    \n",
    "    def __init__(self, vocab_dict):\n",
    "        self.vocab = vocab_dict\n",
    "        \n",
    "        # Id специальных токенов в словаре\n",
    "        self.blank_id = 0\n",
    "        self.bos_id = 1\n",
    "        self.eos_id = 2\n",
    "        self.unk_id = 3\n",
    "        self.word_sep_id = 4 \n",
    "        # word_sep_id должен быть заменен на пробел при декодировании\n",
    "        # и не забудьте удалить пробелы в конце строки!\n",
    "        \n",
    "    def argmax_decode(self, ctc_logits: torch.tensor) -> str:\n",
    "        '''\n",
    "        ctc_logits - ctc-матрица логитов размерности [TIME, VOCAB]\n",
    "        '''\n",
    "        # Здесь должен быть ваш код, который будет оцениваться\n",
    "        raise NotImplemented('Please, implement me!')\n",
    "    \n",
    "    def beam_search_decode(self, ctc_logits: torch.tensor, beam_size: int=16) -> List[str]:\n",
    "        '''\n",
    "        ctc_logits - ctc-матрица логитов размерности [TIME, VOCAB]\n",
    "        beam_size - размер бима(луча)\n",
    "        '''\n",
    "        # Здесь должен быть ваш код, который будет оцениваться\n",
    "        raise NotImplemented('Please, implement me!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bab32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctc_decoder = CTCDecoder(vocab_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af164b4c",
   "metadata": {},
   "source": [
    "## <font color='red'>Внимание!</font> Далее ВЕЗДЕ используем только relative версии рассчета CER / WER и их oracle версии."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646394ee",
   "metadata": {},
   "source": [
    "### Argmax декодинг."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46179f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Рассчитаем усредненный по всему датасету relative CER / WER для ARGMAX варианта декодирования\n",
    "cer_argmax = 0\n",
    "wer_argmax = 0\n",
    "\n",
    "# Здесь должен быть ваш код, который будет оцениваться\n",
    "\n",
    "print(f\"Mean CER in argmax decoding : {cer_argmax}\")\n",
    "print(f\"Mean WER in argmax decoding : {wer_argmax}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce605d8",
   "metadata": {},
   "source": [
    "## Вопрос №1: Как соотносятся WER и CER в задаче ASR?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9dc056",
   "metadata": {},
   "source": [
    "## Ответ: \n",
    "### - {запишите свой ответ, он будет оцениваться}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66735a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Рассчитаем усредненный по всему датасету relative CER / WER для BEAM_SEARCH варианта декодирования\n",
    "# Для рассчета используем beam_size = 1 !!!\n",
    "# Hint : стоит использовать mpire для ускорения\n",
    "cer_bs1 = 0\n",
    "wer_bs1 = 0\n",
    "\n",
    "# Здесь должен быть ваш код, который будет оцениваться\n",
    "\n",
    "print(f\"CER in bs decoding : {cer_bs1}\")\n",
    "print(f\"WER in bs decoding : {wer_bs1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee007ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверим, что мы нигде не ошиблись в написании кода beam_search_decode\n",
    "np.testing.assert_almost_equal(cer_argmax, cer_bs1, decimal=4)\n",
    "np.testing.assert_almost_equal(wer_argmax, wer_bs1, decimal=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b87a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ок, значит все хорошо и можно приступить к построению графиков\n",
    "# зависимости усредненного CER / WER + oracle от beam_size.\n",
    "\n",
    "# Для этого будем использовать beam_size = [4, 8, 16, 32].\n",
    "# Заполним словарик усредненных по датасету relative wer / cer наиболее вероятной гипотезы - top1_wer, top1_cer.\n",
    "# Так же добавим в словарик relative oracle wer / cer - orcale_wer, oracle_cer\n",
    "graph_results = {'oracle_wer':[], 'oracle_cer':[], 'top1_wer':[], 'top1_cer': []}\n",
    "beam_sizes = [4, 8 , 16, 32]\n",
    "for beam_size in beam_sizes:\n",
    "    top1_wer, top1_cer, oracle_wer, oracle_cer = 0, 0\n",
    "    \n",
    "    # Здесь должен быть ваш код, который будет оцениваться\n",
    "    graph_results['top1_cer'].append(top1_cer)\n",
    "    graph_results['top1_wer'].append(top1_wer)\n",
    "    graph_results['oracle_cer'].append(oracle_cer)\n",
    "    graph_results['oracle_wer'].append(oracle_wer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a472e689",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "fig.suptitle('Result of beam_search experiments')\n",
    "\n",
    "axs[0].axhline(y = cer_argmax, color = 'r', linestyle = '-', label='cer_argmax')\n",
    "axs[0].plot(beam_sizes, graph_results['top1_cer'], '--bo', label='top1_cer') \n",
    "axs[0].plot(beam_sizes, graph_results['oracle_cer'], '--go', label='oracle_cer')\n",
    "axs[0].set_title('CER')\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].axhline(y = wer_argmax, color = 'r', linestyle = '-', label='wer_argmax')\n",
    "axs[1].plot(beam_sizes, graph_results['top1_wer'], '--bo', label='top1_wer')\n",
    "axs[1].plot(beam_sizes, graph_results['oracle_wer'], '--bo', label='oracle_wer')\n",
    "axs[1].set_title('WER')\n",
    "axs[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994d69e0",
   "metadata": {},
   "source": [
    "## Вопрос №2: \n",
    "## - Сделайте выводы относительно поведения CER / WER при увеличении размера beam_size? \n",
    "## - Как соотносятся значения relative CER / WER и ORACLE варианты в beam_search ? \n",
    "## - Почему они так соотносятся ? \n",
    "## - Как можно улучшить beam search ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d4bb80",
   "metadata": {},
   "source": [
    "## Ответ: \n",
    "### - {запишите свои ответы, по пунктам они будут оцениваться}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ee02a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}