{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KMy_oLGJgo40"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IaA9fLAYgo43"
   },
   "source": [
    "# Упражнение, для реализации \"Ванильной\" RNN\n",
    "* Попробуем обучить сеть восстанавливать слово hello по первой букве. т.е. построим charecter-level модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "XoqCNUuqgo44"
   },
   "outputs": [],
   "source": [
    "a = torch.ones((3,3))*3\n",
    "b = torch.ones((3,3))*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nNj7xy2-go44",
    "outputId": "ead72e44-9fe1-4fac-dabd-e3dc9fd73d67"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[45., 45., 45.],\n",
       "        [45., 45., 45.],\n",
       "        [45., 45., 45.]])"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "a @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UV7iCZ5Hgo45",
    "outputId": "0134bfc7-732e-48b4-d493-782c6ed21e91"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[15., 15., 15.],\n",
       "        [15., 15., 15.],\n",
       "        [15., 15., 15.]])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "LCCkOtiago45"
   },
   "outputs": [],
   "source": [
    "word = 'ololoasdasddqweqw123456789'\n",
    "#word = 'hello'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ErLwrLysgo46"
   },
   "source": [
    "## Датасет. \n",
    "Позволяет:\n",
    "* Закодировать символ при помощи one-hot\n",
    "* Делать итератор по слову, которыей возвращает текущий символ и следующий как таргет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "qtL5YQCZgo46"
   },
   "outputs": [],
   "source": [
    "class WordDataSet:\n",
    "    \n",
    "    def __init__(self, word):\n",
    "        self.chars2idx = {}\n",
    "        self.indexs  = []\n",
    "        for c in word: \n",
    "            if c not in self.chars2idx:\n",
    "                self.chars2idx[c] = len(self.chars2idx)\n",
    "                \n",
    "            self.indexs.append(self.chars2idx[c])\n",
    "            \n",
    "        self.vec_size = len(self.chars2idx)\n",
    "        self.seq_len  = len(word)\n",
    "        \n",
    "    def get_one_hot(self, idx):\n",
    "        x = torch.zeros(self.vec_size)\n",
    "        x[idx] = 1\n",
    "        return x\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return zip(self.indexs[:-1], self.indexs[1:])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.seq_len\n",
    "    \n",
    "    def get_char_by_id(self, id):\n",
    "        for c, i in self.chars2idx.items():\n",
    "            if id == i: return c\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hVhXi8wmgo48"
   },
   "source": [
    "## Реализация базовой RNN\n",
    "<br/>\n",
    "Скрытый элемент\n",
    "$$ h_t= tanh⁡ (W_{ℎℎ} h_{t−1}+W_{xh} x_t) $$\n",
    "Выход сети\n",
    "\n",
    "$$ y_t = W_{hy} h_t $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "OZLpYZZsgo48"
   },
   "outputs": [],
   "source": [
    "class VanillaRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_size=5, hidden_size=3, out_size=5):\n",
    "        super(VanillaRNN, self).__init__()        \n",
    "        self.x2hidden    = nn.Linear(in_features=in_size, out_features=hidden_size)\n",
    "        self.hidden      = nn.Linear(in_features=hidden_size, out_features=hidden_size)\n",
    "        self.activation  = nn.Tanh()\n",
    "        self.outweight   = nn.Linear(in_features=hidden_size, out_features=out_size)\n",
    "    \n",
    "    def forward(self, x, prev_hidden):\n",
    "        hidden = self.activation(self.x2hidden(x) + self.hidden(prev_hidden))\n",
    "#         Версия без активации - может происходить gradient exploding\n",
    "#         hidden = self.x2hidden(x) + self.hidden(prev_hidden)\n",
    "        output = self.outweight(hidden)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3-JeDzrBgo49"
   },
   "source": [
    "## Инициализация переменных "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qGbIyuCggo49"
   },
   "outputs": [],
   "source": [
    "ds = WordDataSet(word=word)\n",
    "rnn = VanillaRNN(in_size=ds.vec_size, hidden_size=3, out_size=ds.vec_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "e_cnt     = 100\n",
    "optim     = SGD(rnn.parameters(), lr = 0.1, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-m-QDpO1go4-"
   },
   "source": [
    "# Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ehs_wnCmgo4-",
    "outputId": "ecf105ce-93de-4af1-e1c1-25b2e44c2e4f"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "74.68247985839844\n",
      "Clip gradient :  tensor(7.9369)\n",
      "64.46907806396484\n",
      "Clip gradient :  tensor(5.1973)\n",
      "39.70587158203125\n",
      "Clip gradient :  tensor(6.3590)\n",
      "28.357858657836914\n",
      "Clip gradient :  tensor(4.8708)\n",
      "23.596736907958984\n",
      "Clip gradient :  tensor(6.6768)\n",
      "24.970483779907227\n",
      "Clip gradient :  tensor(9.3834)\n",
      "23.081567764282227\n",
      "Clip gradient :  tensor(7.0319)\n",
      "20.046682357788086\n",
      "Clip gradient :  tensor(4.9698)\n",
      "19.071449279785156\n",
      "Clip gradient :  tensor(5.1603)\n",
      "18.277280807495117\n",
      "Clip gradient :  tensor(4.1550)\n"
     ]
    }
   ],
   "source": [
    "CLIP_GRAD = True\n",
    "\n",
    "for epoch in range(e_cnt):\n",
    "    hh = torch.zeros(rnn.hidden.in_features)\n",
    "    loss = 0\n",
    "    optim.zero_grad()\n",
    "    for sample, next_sample in ds:\n",
    "        x = ds.get_one_hot(sample).unsqueeze(0)\n",
    "        target =  torch.LongTensor([next_sample])\n",
    "\n",
    "        y, hh = rnn(x, hh)\n",
    "        \n",
    "        loss += criterion(y, target)\n",
    "     \n",
    "\n",
    "    loss.backward()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print (loss.data.item())\n",
    "        if CLIP_GRAD: print(\"Clip gradient : \", torch.nn.utils.clip_grad_norm_(rnn.parameters(), max_norm=5))\n",
    "    else: \n",
    "        if CLIP_GRAD: torch.nn.utils.clip_grad_norm_(rnn.parameters(), max_norm=1)\n",
    "            \n",
    "#     print(\"Params : \")\n",
    "#     num_params = 0\n",
    "#     for item in rnn.parameters():\n",
    "#         num_params += 1\n",
    "#         print(item.grad)\n",
    "#     print(\"NumParams :\", num_params)\n",
    "#     print(\"Optimize\")\n",
    "    \n",
    "    optim.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bdHsSn7Ygo4_"
   },
   "source": [
    "# Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "id": "D5BDl2xjgo4_",
    "outputId": "a016a752-61d7-4237-e3af-1e2d3df569c3"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Prediction:\t oasddddddddddddddddddddddd\n",
      "Original:\t ololoasdasddqweqw123456789\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AssertionError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-11-612b341693d4>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[0mprint\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;34m'Prediction:\\t'\u001B[0m \u001B[0;34m,\u001B[0m \u001B[0mpredword\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Original:\\t\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mword\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 15\u001B[0;31m \u001B[0;32massert\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpredword\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mword\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "rnn.eval()\n",
    "hh = torch.zeros(rnn.hidden.in_features)\n",
    "id = 0\n",
    "softmax  = nn.Softmax(dim=1)\n",
    "predword = ds.get_char_by_id(id)\n",
    "for c in enumerate(word[:-1]):\n",
    "    x = ds.get_one_hot(id).unsqueeze(0)\n",
    "    y, hh = rnn(x, hh)\n",
    "    y = softmax(y)\n",
    "    m, id = torch.max(y, 1)\n",
    "    id = id.data[0]\n",
    "    predword += ds.get_char_by_id(id)\n",
    "print ('Prediction:\\t' , predword)\n",
    "print(\"Original:\\t\", word)\n",
    "assert(predword == word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rs5Xmaeogo4_"
   },
   "source": [
    "# Практика\n",
    "Реализовать LSTM и GRU модули, обучить их предсказывать тестовое слово"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "omsJ8jZlgo5A"
   },
   "outputs": [],
   "source": [
    "#тестовое слово\n",
    "word = 'ololoasdasddqweqw123456789'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SYL_QESBgo5A"
   },
   "source": [
    "## Реализовать LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "V77Oo2orgo5A"
   },
   "outputs": [],
   "source": [
    "#Написать реализацию LSTM и обучить предсказывать слово\n",
    "class LSTM(nn.Module):\n",
    "  def __init__(self, in_size=5, hidden_size=3, out_size=3):\n",
    "    super().__init__()\n",
    "    self.x_i = nn.Linear(in_features=in_size, out_features=hidden_size)\n",
    "    self.hidden_i = nn.Linear(in_features=hidden_size, out_features=hidden_size)\n",
    "    self.b_i = nn.Parameter(torch.zeros(hidden_size))\n",
    "\n",
    "    self.x_f = nn.Linear(in_features=in_size, out_features=hidden_size)\n",
    "    self.hidden_f = nn.Linear(in_features=hidden_size, out_features=hidden_size)\n",
    "    self.b_f = nn.Parameter(torch.zeros(hidden_size))\n",
    "\n",
    "    self.x_o = nn.Linear(in_features=in_size, out_features=hidden_size)\n",
    "    self.hidden_o = nn.Linear(in_features=hidden_size, out_features=hidden_size)\n",
    "    self.b_o = nn.Parameter(torch.zeros(hidden_size))\n",
    "\n",
    "    self.x_g = nn.Linear(in_features=in_size, out_features=hidden_size)\n",
    "    self.hidden_g = nn.Linear(in_features=hidden_size, out_features=hidden_size)\n",
    "    self.b_g = nn.Parameter(torch.zeros(hidden_size))\n",
    "\n",
    "    self.tanh = nn.Tanh()\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "    self.outweight = nn.Linear(in_features=hidden_size, out_features=out_size)\n",
    "\n",
    "  def forward(self, x, prev_hidden, prev_c):\n",
    "    # print(x.shape, prev_hidden.shape, prev_c.shape)\n",
    "    # print(self.x_i(x).shape, self.hidden_i(prev_hidden).shape, self.b_i.shape)\n",
    "    i = self.sigmoid(self.x_i(x) + self.hidden_i(prev_hidden) + self.b_i)\n",
    "    # print(f\"i.shape = {i.shape}\")\n",
    "    f = self.sigmoid(self.x_f(x) + self.hidden_f(prev_hidden) + self.b_f)\n",
    "    o = self.sigmoid(self.x_o(x) + self.hidden_o(prev_hidden) + self.b_o)\n",
    "    g = self.tanh(self.x_g(x) + self.hidden_g(prev_hidden) + self.b_g)\n",
    "    c_new = f * prev_c + i * g\n",
    "    hidden = self.tanh(c_new) * o\n",
    "    output = self.outweight(hidden)\n",
    "    return output, hidden, c_new"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "ds = WordDataSet(word=word)\n",
    "hidden_size = 10\n",
    "rnn = LSTM(in_size=ds.vec_size, hidden_size=hidden_size, out_size=ds.vec_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(f\"in_size={ds.vec_size}, hidden_size={hidden_size}, out_size={ds.vec_size}\")\n",
    "e_cnt     = 100\n",
    "optim     = SGD(rnn.parameters(), lr = 0.01, momentum=0.9)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "njEMiMeJldnl",
    "outputId": "cacefd7e-5fe5-4a44-8d21-c0027c3f8125"
   },
   "execution_count": 66,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "in_size=17, hidden_size=10, out_size=17\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "CLIP_GRAD = True\n",
    "\n",
    "for epoch in range(e_cnt):\n",
    "  h = torch.zeros(hidden_size)\n",
    "  c = torch.zeros(hidden_size)\n",
    "  loss = 0\n",
    "  optim.zero_grad()\n",
    "  for sample, next_sample in ds:\n",
    "      x = ds.get_one_hot(sample).unsqueeze(0)\n",
    "      target =  torch.LongTensor([next_sample])\n",
    "      \n",
    "      y, h, c = rnn(x, h, c)\n",
    "      loss += criterion(y, target)\n",
    "    \n",
    "\n",
    "  loss.backward()\n",
    "  \n",
    "  if epoch % 10 == 0:\n",
    "      print (loss.data.item())\n",
    "      if CLIP_GRAD: print(\"Clip gradient : \", torch.nn.utils.clip_grad_norm_(rnn.parameters(), max_norm=5))\n",
    "  else: \n",
    "      if CLIP_GRAD: torch.nn.utils.clip_grad_norm_(rnn.parameters(), max_norm=1)\n",
    "          \n",
    "  # print(\"Params : \")\n",
    "  # num_params = 0\n",
    "  # for item in rnn.parameters():\n",
    "  #     num_params += 1\n",
    "  #     print(item.grad)\n",
    "  # print(\"NumParams :\", num_params)\n",
    "  # print(\"Optimize\")\n",
    "  \n",
    "  optim.step()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KNn5m3_Dlwz8",
    "outputId": "b634bb67-b47a-4cad-f11d-80e43b609989"
   },
   "execution_count": 74,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9.27072811126709\n",
      "Clip gradient :  tensor(10.2192)\n",
      "8.737988471984863\n",
      "Clip gradient :  tensor(9.6936)\n",
      "8.270630836486816\n",
      "Clip gradient :  tensor(9.2256)\n",
      "7.806108474731445\n",
      "Clip gradient :  tensor(8.8226)\n",
      "7.365233421325684\n",
      "Clip gradient :  tensor(8.5298)\n",
      "6.929915904998779\n",
      "Clip gradient :  tensor(8.0776)\n",
      "6.506451606750488\n",
      "Clip gradient :  tensor(8.1888)\n",
      "6.0715155601501465\n",
      "Clip gradient :  tensor(7.2475)\n",
      "5.6868157386779785\n",
      "Clip gradient :  tensor(8.0842)\n",
      "5.249034881591797\n",
      "Clip gradient :  tensor(6.4048)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "rnn.eval()\n",
    "h = torch.zeros(hidden_size)\n",
    "c = torch.zeros(hidden_size)\n",
    "id = 0\n",
    "softmax  = nn.Softmax(dim=1)\n",
    "predword = ds.get_char_by_id(id)\n",
    "for _c in enumerate(word[:-1]):\n",
    "    x = ds.get_one_hot(id).unsqueeze(0)\n",
    "    y, h, c = rnn(x, h, c)\n",
    "    y = softmax(y)\n",
    "    m, id = torch.max(y, 1)\n",
    "    id = id.data[0]\n",
    "    predword += ds.get_char_by_id(id)\n",
    "print ('Prediction:\\t' , predword)\n",
    "print(\"Original:\\t\", word)\n",
    "assert(predword == word)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dNCUgGZUAsOv",
    "outputId": "ad9cbead-e037-48ef-eb8f-7576c88979e5"
   },
   "execution_count": 79,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Prediction:\t ololoasdasddqweqw123456789\n",
      "Original:\t ololoasdasddqweqw123456789\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05dhrXRSgo5A"
   },
   "source": [
    "## Реализовать GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "6ZfZeaS_go5A"
   },
   "outputs": [],
   "source": [
    "#Написать реализацию GRU и обучить предсказывать слово\n",
    "class GRU(nn.Module):\n",
    "  def __init__(self, in_size=5, hidden_size=3, out_size=3):\n",
    "    super().__init__()\n",
    "    self.x_u = nn.Linear(in_features=in_size, out_features=hidden_size)\n",
    "    self.hidden_u = nn.Linear(in_features=hidden_size, out_features=hidden_size)\n",
    "    self.b_u = nn.Parameter(torch.zeros(hidden_size))\n",
    "\n",
    "    self.x_r = nn.Linear(in_features=in_size, out_features=hidden_size)\n",
    "    self.hidden_r = nn.Linear(in_features=hidden_size, out_features=hidden_size)\n",
    "    self.b_r = nn.Parameter(torch.zeros(hidden_size))\n",
    "\n",
    "    self.x_h = nn.Linear(in_features=in_size, out_features=hidden_size)\n",
    "    self.hidden_h = nn.Linear(in_features=hidden_size, out_features=hidden_size)\n",
    "    self.b_h = nn.Parameter(torch.zeros(hidden_size))\n",
    "\n",
    "    self.tanh = nn.Tanh()\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "    self.outweight = nn.Linear(in_features=hidden_size, out_features=out_size)\n",
    "\n",
    "  def forward(self, x, prev_hidden, prev_c):\n",
    "    u = self.sigmoid(self.x_u(x) + self.hidden_u(prev_hidden) + self.b_u)\n",
    "    r = self.sigmoid(self.x_r(x) + self.hidden_r(prev_hidden) + self.b_r)\n",
    "    __h = r * prev_hidden\n",
    "    _h = self.tanh(self.x_h(x) + self.hidden_h(__h))\n",
    "    h = (1 - u) * _h + u * prev_hidden\n",
    "    output = self.outweight(h)\n",
    "    return output, h"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "ds = WordDataSet(word=word)\n",
    "hidden_size = 10\n",
    "rnn = GRU(in_size=ds.vec_size, hidden_size=hidden_size, out_size=ds.vec_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(f\"in_size={ds.vec_size}, hidden_size={hidden_size}, out_size={ds.vec_size}\")\n",
    "e_cnt     = 100\n",
    "optim     = SGD(rnn.parameters(), lr = 0.01, momentum=0.9)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UvrxQstbC9pu",
    "outputId": "2da72dcd-9285-49ac-a9c2-b52ea17ae950"
   },
   "execution_count": 83,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "in_size=17, hidden_size=10, out_size=17\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "CLIP_GRAD = True\n",
    "\n",
    "for epoch in range(e_cnt):\n",
    "  h = torch.zeros(hidden_size)\n",
    "  \n",
    "  loss = 0\n",
    "  optim.zero_grad()\n",
    "  for sample, next_sample in ds:\n",
    "      x = ds.get_one_hot(sample).unsqueeze(0)\n",
    "      target =  torch.LongTensor([next_sample])\n",
    "      c = torch.zeros(hidden_size)\n",
    "      y, h = rnn(x, h, c)\n",
    "      loss += criterion(y, target)\n",
    "    \n",
    "\n",
    "  loss.backward()\n",
    "  \n",
    "  if epoch % 10 == 0:\n",
    "      print (loss.data.item())\n",
    "      if CLIP_GRAD: print(\"Clip gradient : \", torch.nn.utils.clip_grad_norm_(rnn.parameters(), max_norm=5))\n",
    "  else: \n",
    "      if CLIP_GRAD: torch.nn.utils.clip_grad_norm_(rnn.parameters(), max_norm=1)\n",
    "          \n",
    "  # print(\"Params : \")\n",
    "  # num_params = 0\n",
    "  # for item in rnn.parameters():\n",
    "  #     num_params += 1\n",
    "  #     print(item.grad)\n",
    "  # print(\"NumParams :\", num_params)\n",
    "  # print(\"Optimize\")\n",
    "  \n",
    "  optim.step()"
   ],
   "metadata": {
    "id": "Cw2-b5Y2EmiT",
    "outputId": "9a3a64b3-0e0f-43c7-bccd-189058555f16",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 84,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "72.42302703857422\n",
      "Clip gradient :  tensor(4.6419)\n",
      "69.8535385131836\n",
      "Clip gradient :  tensor(3.5886)\n",
      "66.83639526367188\n",
      "Clip gradient :  tensor(3.2351)\n",
      "63.54423522949219\n",
      "Clip gradient :  tensor(3.7836)\n",
      "58.882816314697266\n",
      "Clip gradient :  tensor(4.7286)\n",
      "52.84427261352539\n",
      "Clip gradient :  tensor(5.1046)\n",
      "46.27897262573242\n",
      "Clip gradient :  tensor(5.2396)\n",
      "39.647979736328125\n",
      "Clip gradient :  tensor(5.0810)\n",
      "33.375\n",
      "Clip gradient :  tensor(5.0499)\n",
      "27.126129150390625\n",
      "Clip gradient :  tensor(4.9527)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "rnn.eval()\n",
    "h = torch.zeros(hidden_size)\n",
    "id = 0\n",
    "softmax  = nn.Softmax(dim=1)\n",
    "predword = ds.get_char_by_id(id)\n",
    "for _c in enumerate(word[:-1]):\n",
    "    x = ds.get_one_hot(id).unsqueeze(0)\n",
    "    c = torch.zeros(hidden_size)\n",
    "    y, h = rnn(x, h, c)\n",
    "    y = softmax(y)\n",
    "    m, id = torch.max(y, 1)\n",
    "    id = id.data[0]\n",
    "    predword += ds.get_char_by_id(id)\n",
    "print ('Prediction:\\t' , predword)\n",
    "print(\"Original:\\t\", word)\n",
    "assert(predword == word)"
   ],
   "metadata": {
    "id": "5XXr_je7E0Ax",
    "outputId": "0dcc51f0-80ae-405b-b281-37c370e65b54",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 86,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Prediction:\t ololoasdasddqweqw123456789\n",
      "Original:\t ololoasdasddqweqw123456789\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "uehB7ffRE3gl"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "colab": {
   "provenance": [],
   "collapsed_sections": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}